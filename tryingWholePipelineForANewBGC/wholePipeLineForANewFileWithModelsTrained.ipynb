{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Obtaining hmmer input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "nameOfTheCluster = \"BGC0001720\" ##Change this line with the  BGC you are trying to use as the input\n",
    "genbankFile = open (nameOfTheCluster + \".gbk\")\n",
    "hmmerInputFile = open (\"hmmerInput.fasta\",\"w\")\n",
    "sequence = \"\"\n",
    "flag = False\n",
    "for line in genbankFile:\n",
    "    line = line.strip(\"\\n\")\n",
    "    line = line.replace(\" \",\"\")\n",
    "    if flag == True:\n",
    "        sequence += line.strip('\"')\n",
    "        if line[-1] == '\"':\n",
    "            flag =False ##A CDS is found and the flag is turned of, now it looks for the CDS sequence\n",
    "            hmmerInputFile.write(\">\" + nameOfTheCluster + \"\\n\" + sequence + \"\\n\")\n",
    "            sequence = \"\"\n",
    "    elif line[0:12] == \"/translation\": ##Every time it founds this, the sequence is added to the output file and the flag for looking for new CDS is turned on again\n",
    "        sequence += line [14:]\n",
    "        flag = True\n",
    "genbankFile.close()\n",
    "hmmerInputFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Obtaining hmmer output. This is commented out if the user does not have hmmer. The hmmer output for BGC 1720 is provided in github\n",
    "import os\n",
    "#os.system(\"hmmscan Pfam-A.hmm hmmerinput.fasta > hmmeroutput.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Creating pfam counts\n",
    "inputFile = open (\"hmmeroutput.txt\",\"r\")\n",
    "foundPfams=[] ##This list contains the pfam domains found in the BGC\n",
    "for line in inputFile:\n",
    "     if line[:3]==\">> \":\n",
    "            domainName=line[3:].split(\" \")[0]\n",
    "            if domainName not in foundPfams:\n",
    "                foundPfams.append(domainName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "allPfamDomains=[] ##This list contains all the pfam domains used in the training of the model (6159)\n",
    "pfamDomainsFile = open (\"listOfDomains.txt\")\n",
    "for line in pfamDomainsFile:\n",
    "    allPfamDomains.append(line.strip(\"\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfamVector = \"\" ##Assigns 1s to Pfams founds in the BGC and 0 to Pfams not found in the BGC\n",
    "for domain in allPfamDomains:\n",
    "    if domain in foundPfams:\n",
    "        pfamVector += \"1\"\n",
    "    else:\n",
    "        pfamVector += \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "##obtainingFingerprint\n",
    "from rdkit import Chem ##These lines parse all the substrucutres in the smart file and also creates a molecule from the smiles included in the json file of the BGC\n",
    "smartFile = open (\"smartMolecules.tsv\")\n",
    "smartStringList=[]\n",
    "smartMoleculeList=[]\n",
    "for line in smartFile:\n",
    "    line=line.strip(\"\\n\")\n",
    "    line=line.split(\"\\t\")\n",
    "    smartStringList.append(line[2])\n",
    "smartFile.close()\n",
    "for smartString in smartStringList:\n",
    "    m=Chem.MolFromSmarts(smartString)\n",
    "    smartMoleculeList.append(m)\n",
    "smileFile = open (nameOfTheCluster + \".json\")\n",
    "for line in smileFile:\n",
    "    line=line.strip()\n",
    "    if line[0:14]=='\"chem_struct\":':\n",
    "            smileMolecule= Chem.MolFromSmiles(line [16:-2])\n",
    "smileFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "fingerprintVector = \"\" ##Creates the fingerprint, 1s for substructures found in the smile string and 0 for substructures not found. The length is 306\n",
    "for i in range (0, len(smartMoleculeList)):\n",
    "    if (smileMolecule.HasSubstructMatch(smartMoleculeList[i])):\n",
    "        fingerprintVector += \"1\"\n",
    "    else:\n",
    "        fingerprintVector += \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "##IOKR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np ##Trial pfam and trial fingerprint contains the correct input and output for our new BGC\n",
    "trialPfam = pfamVector\n",
    "trialFingerprint = fingerprintVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertStringIntoVector (String):##Receives a binary vector in the form of a String and returns a numpy array\n",
    "    intoList=list(String)\n",
    "    vector=np.asarray(intoList,dtype=int)\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "testIndexesForIOKR = np.load(\"testSetIndexesForTrainedModelIOKR.npy\") ##Loads the files from the previously trained algorithm\n",
    "trainingIndexesForIOKR = np.load(\"trainingSetIndexesForTrainedModelIOKR.npy\")\n",
    "inverseMatrixForIOKR = np.load(\"inverseMatrixForTrainedModelIOKR.npy\")\n",
    "dimensionTrainingSet = len(trainingIndexesForIOKR)\n",
    "##Opens the two files and creates one list of Strings for pfam and another one for fingerprints\n",
    "pfamFile= open (\"pfamDomains0and1ForAllClusters.txt\")\n",
    "pfamList=[]##List of Strings\n",
    "for line in pfamFile:\n",
    "    line=line.strip(\"\\n\")\n",
    "    pfamList.append(line[11:])\n",
    "pfamFile.close()\n",
    "fingerprintFile=open (\"fingerPrintsForIndividualClustersNOT478.txt\")\n",
    "fingerprintList=[]##List of strings\n",
    "for line in fingerprintFile:\n",
    "    line=line.strip(\"\\n\")\n",
    "    fingerprintList.append(line[11:])\n",
    "fingerprintFile.close()\n",
    "##Converts the Lists of strings into list of Vectors\n",
    "pfamVectorList=[]#List of vectors\n",
    "for pfamString in pfamList:\n",
    "    pfamVectorList.append(convertStringIntoVector(pfamString))\n",
    "fingerprintVectorList=[]##List of vectors\n",
    "for fingerprintString in fingerprintList:\n",
    "    fingerprintVectorList.append(convertStringIntoVector(fingerprintString))\n",
    "trialPfam = convertStringIntoVector(trialPfam)\n",
    "trialFingerprint = convertStringIntoVector(trialFingerprint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "##The gammas of both kernels were optimised for using IOKR with pfam counts\n",
    "def gaussianKernelForPfam (vector1, vector2):##Does the gaussian Kernel for two pfam vectors\n",
    "    gamma=0.003\n",
    "    euclideanDistance=np.linalg.norm(vector1-vector2)\n",
    "    kernelValue=np.exp(-gamma*(euclideanDistance**2))\n",
    "    return kernelValue\n",
    "def gaussianKernelForFingerprint (vector1, vector2):##Does the gaussian kernel for two fingerprint vectors. \n",
    "    gamma=0.1\n",
    "    euclideanDistance=np.linalg.norm(vector1-vector2)\n",
    "    kernelValue=np.exp(-gamma*(euclideanDistance**2))\n",
    "    return kernelValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfamTest = [pfamVectorList[i] for i in testIndexesForIOKR]##Recovers the test set from when the model was trained\n",
    "pfamTest.append(trialPfam)##and adds the new file Pfam vector\n",
    "fingerprintTest = [fingerprintVectorList[i] for i in testIndexesForIOKR]##Does the same for the fingerprints\n",
    "fingerprintTest.append(trialFingerprint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculatingIOKRScore (j): ##Gives the score of the IOKR formula depending on the position in the list of both pfam vectors and fingerprint vectors. Then J=206, it is the one from the new file.\n",
    "    ky=np.zeros((dimensionTrainingSet,1))##kx lower case\n",
    "    kx=np.zeros((dimensionTrainingSet,1))##ky lower case\n",
    "    for i in range (0,dimensionTrainingSet):\n",
    "        iIndex=trainingIndexesForIOKR[i]\n",
    "        kx[i]=gaussianKernelForPfam(pfamVectorList[iIndex],pfamTest[len(pfamTest)-1])\n",
    "        ky[i]=gaussianKernelForFingerprint(fingerprintVectorList[iIndex],fingerprintTest[j])\n",
    "    kyt=np.transpose(ky)##Transposing ky\n",
    "    ##Inverse matrix was loaded from a file some cells ago. As that part comes from the original training of the algorithm.\n",
    "    result= np.matmul(np.matmul(kyt,inverseMatrixForIOKR), kx)##Returns a number when doing the multiplication of the matrixes\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = np.zeros(207) ##Gives a score for each training of the test set. When J=206, it is the expected output vector we have to rank\n",
    "for j in range (0, 207):\n",
    "    score[j]= calculatingIOKRScore(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The correct output has been ranked Top 1\n"
     ]
    }
   ],
   "source": [
    "selfScore = score[len(score)-1] ##Our trial vector is the last on the list\n",
    "pos = 1 ##The initial position is first, for each other vector with a better score than ours, the position will be decreased one unit. If another vector gets the same score, it is not decreased as probably it has the same fingerprint than ours.\n",
    "for i in range (0, len(score)):\n",
    "    if score[i] >selfScore:\n",
    "        pos +=1\n",
    "print (\"The correct output has been ranked Top %d\" % pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Down below are shown the top 3 fingerprint predictions:\n",
      "\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0\n",
      " 0 0 1 1 1 1 0 0 0 1]\n",
      "\n",
      "\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0\n",
      " 0 0 1 1 0 1 0 0 0 1]\n",
      "\n",
      "\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 1 0 0 0 0 0 1]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## np.argsort gives us the index of results ordered from the lowest score to the highest one.\n",
    "print (\"Down below are shown the top 3 fingerprint predictions:\\n\")\n",
    "for i in [-1,-2,-3]:\n",
    "    print (fingerprintTest[np.argsort (score)[i]])\n",
    "    print (\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "numberOfClusters = len(pfamVectorList) ##This will be 1031, but this script can be used with other models already trained with more BGCs\n",
    "pfamVectorList=np.concatenate(pfamVectorList,axis=0)\n",
    "xData=pfamVectorList.reshape(numberOfClusters,6159)\n",
    "fingerprintVectorList=np.concatenate(fingerprintVectorList,axis=0)\n",
    "yData=fingerprintVectorList.reshape(numberOfClusters,306)\n",
    "#The reshape puts the data as one row for each training example. It is necessary for keras\n",
    "testIndexesForNN = np.load(\"testSetIndexesForTrainedModelNN.npy\")\n",
    "xTestData = [xData[i] for i in testIndexesForNN] ##The same test data than in the training is used\n",
    "yTestData = [yData[i] for i in testIndexesForNN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0807 14:09:05.679498 10760 deprecation_wrapper.py:119] From C:\\Users\\Yoo\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0807 14:09:05.756479 10760 deprecation_wrapper.py:119] From C:\\Users\\Yoo\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4115: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "W0807 14:09:06.238243 10760 deprecation_wrapper.py:119] From C:\\Users\\Yoo\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0807 14:09:06.239239 10760 deprecation_wrapper.py:119] From C:\\Users\\Yoo\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0807 14:09:06.240238 10760 deprecation_wrapper.py:119] From C:\\Users\\Yoo\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "W0807 14:09:07.184556 10760 deprecation_wrapper.py:119] From C:\\Users\\Yoo\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0807 14:09:07.196528 10760 deprecation.py:323] From C:\\Users\\Yoo\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.models import load_model\n",
    "model = load_model('neuralnetworkmodel.h5')##This file could not be uploaded to github because it is around 500 mb. If you want to try this model you should train it yourself and save the model already trained with \"model.save(neuralnetworkmodel)\"\n",
    "trialPfam =trialPfam.reshape(1,6159)##Important to give the input for the prediction as the matrix even if using only one vector\n",
    "predictedFingerprint = model.predict(trialPfam)##Gives you the predicted fingerprint for that input with the model\n",
    "for j in range (0, len (predictedFingerprint[0])):##Rounds up and down all the predictions to 1 and 0 to obtain the fingerprint\n",
    "        if predictedFingerprint[0][j]<0.5:\n",
    "            predictedFingerprint[0][j] = 0\n",
    "        else:\n",
    "            predictedFingerprint[0][j] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussianKernel (vector1, vector2):##Does the gaussian Kernel for two vectors\n",
    "    gamma=0.1\n",
    "    euclideanDistance=np.linalg.norm(vector1-vector2)\n",
    "    kernelValue=np.exp(-gamma*(euclideanDistance**2))\n",
    "    return kernelValue\n",
    "score = np.zeros(207)\n",
    "score[206]=gaussianKernel(predictedFingerprint,trialFingerprint) ##This is the one with the correct output from the file\n",
    "for j in range (0, 206):\n",
    "    score[j]= gaussianKernel(predictedFingerprint,yTestData[j]) ##This are the scores with the test vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The correct output has been ranked Top 1\n"
     ]
    }
   ],
   "source": [
    "selfScore = score[len(score)-1] ##Our trial vector is the last on the list\n",
    "pos = 1##The initial position is first, for each other vector with a better score than ours, the position will be decreased one unit. If another vector gets the same score, it is not decreased as probably it has the same fingerprint than ours.\n",
    "for i in range (0, len(score)):\n",
    "    if score[i] >selfScore:\n",
    "        pos +=1\n",
    "print (\"The correct output has been ranked Top %d\" % pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Down below are shown the top 3 fingerprint predictions:\n",
      "\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0\n",
      " 0 0 1 1 1 1 0 0 0 1]\n",
      "\n",
      "\n",
      "[1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0\n",
      " 0 0 1 1 1 1 0 1 0 1]\n",
      "\n",
      "\n",
      "[1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0\n",
      " 0 0 1 1 0 1 0 0 0 1]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## np.argsort gives us the index of results ordered from the lowest score to the highest one.\n",
    "print (\"Down below are shown the top 3 fingerprint predictions:\\n\")\n",
    "for i in [-1,-2,-3]:\n",
    "    if np.argsort (score)[i] == 206:\n",
    "        print (trialFingerprint)\n",
    "    else:\n",
    "        print (yTestData[np.argsort (score)[i]])\n",
    "    print (\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
