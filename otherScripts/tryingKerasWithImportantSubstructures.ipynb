{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Gets around 23-28% top1 with ADAM optimiser and binarry crossentropy as the lost function\n",
    "##This script is used for reduced CDK fingerprints in which positions with more than 99% of 1s or 0s had been chopped out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yoo\\Desktop\\summerProject\\hmmer-3.2.1\\trial\\usefulFiles\\machineLearningKernelPfamFingerPrints\n"
     ]
    }
   ],
   "source": [
    "cd C:\\Users\\Yoo\\Desktop\\summerProject\\hmmer-3.2.1\\trial\\usefulFiles\\machineLearningKernelPfamFingerPrints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertStringIntoVector (String):##Receives a binary vector in the form of a String\n",
    "    intoList=list(String)\n",
    "    vector=np.asarray(intoList,dtype=int)\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splittingTrainingDataIntoXAndY (filesData):##Receives a list in which element has as [0] the X and as [1] the Y\n",
    "    xData=[]\n",
    "    yData=[]\n",
    "    for element in filesData:\n",
    "        xData.append(element[0])\n",
    "        yData.append(element[1])\n",
    "    return xData, yData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "filesData=[]\n",
    "numberOfClusters=0\n",
    "XFile=open(\"pfamDomains0and1ForAllClusters.txt\")\n",
    "YFile=open(\"fingerprintsWithoutOnly0or1Positions.txt\")\n",
    "for pfam, fingerprint in zip(XFile,YFile): ##Reads the two files at the same time and adds each thing to the same list\n",
    "    pfam=pfam.strip(\"\\n\")\n",
    "    fingerprint=fingerprint.strip(\"\\n\")\n",
    "    filesData.append([convertStringIntoVector(pfam[11:]),convertStringIntoVector(fingerprint[11:])])\n",
    "    numberOfClusters+=1\n",
    "XFile.close()\n",
    "YFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "xData,yData = splittingTrainingDataIntoXAndY(filesData)##Now the list is splitted into X and Y data\n",
    "xData=np.concatenate(xData,axis=0)\n",
    "xData=xData.reshape(numberOfClusters,6159)\n",
    "yData=np.concatenate(yData,axis=0)\n",
    "yData=yData.reshape(numberOfClusters,104)##Put 306 if using full fingerprints\n",
    "#The reshape puts the data as one row for each training example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "#Creates a list of Random Numbers as big as the number of Clusters we have\n",
    "#Then we will select which ones we have for each subset\n",
    "listOfRandomNumbers=random.sample(range(numberOfClusters), numberOfClusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTestData = np.asarray([xData[i] for i in listOfRandomNumbers[618:824]],dtype=int)\n",
    "yTestData = np.asarray([yData[i] for i in listOfRandomNumbers[618:824]],dtype=int)\n",
    "xTrainingData = np.asarray([xData[i] for i in (listOfRandomNumbers[:618]+listOfRandomNumbers[824:])],dtype=int)\n",
    "yTrainingData = np.asarray([yData[i]for i in (listOfRandomNumbers[:618]+listOfRandomNumbers[824:])],dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras import optimizers\n",
    "from keras import initializers\n",
    "lr=0.02\n",
    "nn=[6159, 20, 104]\n",
    "##The weights are saved and loaded each time the learning rate is changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "825/825 [==============================] - 22s 26ms/step - loss: 0.4659 - binary_crossentropy: 0.4659\n",
      "Epoch 2/30\n",
      "825/825 [==============================] - 18s 22ms/step - loss: 0.3343 - binary_crossentropy: 0.3343\n",
      "Epoch 3/30\n",
      "825/825 [==============================] - 18s 21ms/step - loss: 0.3091 - binary_crossentropy: 0.3091\n",
      "Epoch 4/30\n",
      "825/825 [==============================] - 17s 21ms/step - loss: 0.2919 - binary_crossentropy: 0.2919\n",
      "Epoch 5/30\n",
      "825/825 [==============================] - 17s 21ms/step - loss: 0.2770 - binary_crossentropy: 0.2770\n",
      "Epoch 6/30\n",
      "825/825 [==============================] - 17s 21ms/step - loss: 0.2726 - binary_crossentropy: 0.2726\n",
      "Epoch 7/30\n",
      "825/825 [==============================] - 16s 20ms/step - loss: 0.2659 - binary_crossentropy: 0.2659\n",
      "Epoch 8/30\n",
      "825/825 [==============================] - 15s 18ms/step - loss: 0.2643 - binary_crossentropy: 0.2643\n",
      "Epoch 9/30\n",
      "825/825 [==============================] - 15s 18ms/step - loss: 0.2571 - binary_crossentropy: 0.2571\n",
      "Epoch 10/30\n",
      "825/825 [==============================] - 15s 18ms/step - loss: 0.2539 - binary_crossentropy: 0.2539\n",
      "Epoch 11/30\n",
      "825/825 [==============================] - 15s 18ms/step - loss: 0.2491 - binary_crossentropy: 0.2491\n",
      "Epoch 12/30\n",
      "825/825 [==============================] - 15s 18ms/step - loss: 0.2470 - binary_crossentropy: 0.2470\n",
      "Epoch 13/30\n",
      "825/825 [==============================] - 15s 18ms/step - loss: 0.2448 - binary_crossentropy: 0.2448\n",
      "Epoch 14/30\n",
      "825/825 [==============================] - 15s 18ms/step - loss: 0.2464 - binary_crossentropy: 0.2464\n",
      "Epoch 15/30\n",
      "825/825 [==============================] - 15s 18ms/step - loss: 0.2451 - binary_crossentropy: 0.2451\n",
      "Epoch 16/30\n",
      "825/825 [==============================] - 15s 18ms/step - loss: 0.2415 - binary_crossentropy: 0.2415\n",
      "Epoch 17/30\n",
      "825/825 [==============================] - 15s 18ms/step - loss: 0.2392 - binary_crossentropy: 0.2392\n",
      "Epoch 18/30\n",
      "825/825 [==============================] - 15s 18ms/step - loss: 0.2369 - binary_crossentropy: 0.2369\n",
      "Epoch 19/30\n",
      "825/825 [==============================] - 15s 18ms/step - loss: 0.2364 - binary_crossentropy: 0.2364\n",
      "Epoch 20/30\n",
      "825/825 [==============================] - 15s 18ms/step - loss: 0.2379 - binary_crossentropy: 0.2379\n",
      "Epoch 21/30\n",
      "825/825 [==============================] - 15s 18ms/step - loss: 0.2441 - binary_crossentropy: 0.2441\n",
      "Epoch 22/30\n",
      "825/825 [==============================] - 15s 18ms/step - loss: 0.2387 - binary_crossentropy: 0.2387\n",
      "Epoch 23/30\n",
      "825/825 [==============================] - 15s 18ms/step - loss: 0.2387 - binary_crossentropy: 0.2387\n",
      "Epoch 24/30\n",
      "825/825 [==============================] - 15s 18ms/step - loss: 0.2407 - binary_crossentropy: 0.2407\n",
      "Epoch 25/30\n",
      "825/825 [==============================] - 15s 18ms/step - loss: 0.2435 - binary_crossentropy: 0.2435\n",
      "Epoch 26/30\n",
      "825/825 [==============================] - 15s 18ms/step - loss: 0.2424 - binary_crossentropy: 0.2424\n",
      "Epoch 27/30\n",
      "825/825 [==============================] - 15s 18ms/step - loss: 0.2400 - binary_crossentropy: 0.2400\n",
      "Epoch 28/30\n",
      "825/825 [==============================] - 15s 18ms/step - loss: 0.2368 - binary_crossentropy: 0.2368\n",
      "Epoch 29/30\n",
      "825/825 [==============================] - 15s 18ms/step - loss: 0.2384 - binary_crossentropy: 0.2384\n",
      "Epoch 30/30\n",
      "825/825 [==============================] - 15s 18ms/step - loss: 0.2433 - binary_crossentropy: 0.2433\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(nn[0], input_dim=6159, activation = 'relu', kernel_initializer=initializers.random_normal(stddev=0.1) ))\n",
    "model.add(Dense(nn[1], activation = 'relu', kernel_initializer=initializers.random_normal(stddev=0.1)))\n",
    "model.add(Dense(nn[1], activation = 'relu',kernel_initializer=initializers.random_normal(stddev=0.1)))\n",
    "model.add(Dense(nn[1], activation = 'relu',kernel_initializer=initializers.random_normal(stddev=0.1)))\n",
    "model.add(Dense(nn[2], activation = 'sigmoid',kernel_initializer=initializers.random_normal(stddev=0.1)))\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizers.adam(lr=lr), metrics = ['binary_crossentropy'])\n",
    "model.fit(xTrainingData, yTrainingData, epochs=30)\n",
    "model.save_weights('trial.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "825/825 [==============================] - 18s 22ms/step - loss: 0.2331 - binary_crossentropy: 0.2331\n",
      "Epoch 2/20\n",
      "825/825 [==============================] - 16s 19ms/step - loss: 0.2210 - binary_crossentropy: 0.2210\n",
      "Epoch 3/20\n",
      "825/825 [==============================] - 17s 21ms/step - loss: 0.2164 - binary_crossentropy: 0.2164\n",
      "Epoch 4/20\n",
      "825/825 [==============================] - 17s 20ms/step - loss: 0.2138 - binary_crossentropy: 0.2138\n",
      "Epoch 5/20\n",
      "825/825 [==============================] - 17s 20ms/step - loss: 0.2117 - binary_crossentropy: 0.2117\n",
      "Epoch 6/20\n",
      "825/825 [==============================] - 17s 21ms/step - loss: 0.2097 - binary_crossentropy: 0.2097\n",
      "Epoch 7/20\n",
      "825/825 [==============================] - 17s 20ms/step - loss: 0.2081 - binary_crossentropy: 0.2081\n",
      "Epoch 8/20\n",
      "825/825 [==============================] - 16s 20ms/step - loss: 0.2066 - binary_crossentropy: 0.2066\n",
      "Epoch 9/20\n",
      "825/825 [==============================] - 16s 19ms/step - loss: 0.2056 - binary_crossentropy: 0.2056\n",
      "Epoch 10/20\n",
      "825/825 [==============================] - 17s 20ms/step - loss: 0.2047 - binary_crossentropy: 0.2047\n",
      "Epoch 11/20\n",
      "825/825 [==============================] - 17s 21ms/step - loss: 0.2039 - binary_crossentropy: 0.2039\n",
      "Epoch 12/20\n",
      "825/825 [==============================] - 17s 21ms/step - loss: 0.2036 - binary_crossentropy: 0.2036\n",
      "Epoch 13/20\n",
      "825/825 [==============================] - 17s 21ms/step - loss: 0.2024 - binary_crossentropy: 0.2024\n",
      "Epoch 14/20\n",
      "825/825 [==============================] - 17s 21ms/step - loss: 0.2014 - binary_crossentropy: 0.2014\n",
      "Epoch 15/20\n",
      "825/825 [==============================] - 17s 21ms/step - loss: 0.2007 - binary_crossentropy: 0.2007\n",
      "Epoch 16/20\n",
      "825/825 [==============================] - 17s 21ms/step - loss: 0.2001 - binary_crossentropy: 0.2001\n",
      "Epoch 17/20\n",
      "825/825 [==============================] - 17s 21ms/step - loss: 0.1996 - binary_crossentropy: 0.1996\n",
      "Epoch 18/20\n",
      "825/825 [==============================] - 17s 21ms/step - loss: 0.1994 - binary_crossentropy: 0.1994\n",
      "Epoch 19/20\n",
      "825/825 [==============================] - 17s 21ms/step - loss: 0.1994 - binary_crossentropy: 0.1994\n",
      "Epoch 20/20\n",
      "825/825 [==============================] - 17s 21ms/step - loss: 0.1984 - binary_crossentropy: 0.1984\n"
     ]
    }
   ],
   "source": [
    "##We save the weights and repeat the process with a smaller learning rate\n",
    "lr=0.003\n",
    "model=Sequential()\n",
    "model.add(Dense(nn[0], input_dim=6159, activation = 'relu', kernel_initializer=initializers.random_normal(stddev=0.1) ))\n",
    "model.add(Dense(nn[1], activation = 'relu', kernel_initializer=initializers.random_normal(stddev=0.1)))\n",
    "model.add(Dense(nn[1], activation = 'relu',kernel_initializer=initializers.random_normal(stddev=0.1)))\n",
    "model.add(Dense(nn[1], activation = 'relu',kernel_initializer=initializers.random_normal(stddev=0.1)))\n",
    "model.add(Dense(nn[2], activation = 'sigmoid',kernel_initializer=initializers.random_normal(stddev=0.1)))\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizers.adam(lr=lr), metrics = ['binary_crossentropy'])\n",
    "from keras.models import load_model\n",
    "model.load_weights(\"trial.h5\")\n",
    "model.fit(xTrainingData, yTrainingData, epochs=20)\n",
    "model.save_weights('trial.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "825/825 [==============================] - 21s 25ms/step - loss: 0.1967 - binary_crossentropy: 0.1967\n",
      "Epoch 2/20\n",
      "825/825 [==============================] - 17s 21ms/step - loss: 0.1953 - binary_crossentropy: 0.1953\n",
      "Epoch 3/20\n",
      "825/825 [==============================] - 17s 21ms/step - loss: 0.1947 - binary_crossentropy: 0.1947\n",
      "Epoch 4/20\n",
      "825/825 [==============================] - 17s 21ms/step - loss: 0.1942 - binary_crossentropy: 0.1942\n",
      "Epoch 5/20\n",
      "825/825 [==============================] - 17s 21ms/step - loss: 0.1940 - binary_crossentropy: 0.1940\n",
      "Epoch 6/20\n",
      "825/825 [==============================] - 17s 21ms/step - loss: 0.1936 - binary_crossentropy: 0.1936\n",
      "Epoch 7/20\n",
      "825/825 [==============================] - 17s 21ms/step - loss: 0.1933 - binary_crossentropy: 0.1933\n",
      "Epoch 8/20\n",
      "825/825 [==============================] - 18s 22ms/step - loss: 0.1929 - binary_crossentropy: 0.1929\n",
      "Epoch 9/20\n",
      "825/825 [==============================] - 18s 22ms/step - loss: 0.1927 - binary_crossentropy: 0.1927\n",
      "Epoch 10/20\n",
      "825/825 [==============================] - 19s 23ms/step - loss: 0.1925 - binary_crossentropy: 0.1925\n",
      "Epoch 11/20\n",
      "825/825 [==============================] - 17s 21ms/step - loss: 0.1923 - binary_crossentropy: 0.1923\n",
      "Epoch 12/20\n",
      "825/825 [==============================] - 17s 21ms/step - loss: 0.1920 - binary_crossentropy: 0.1920\n",
      "Epoch 13/20\n",
      "825/825 [==============================] - 17s 21ms/step - loss: 0.1918 - binary_crossentropy: 0.1918\n",
      "Epoch 14/20\n",
      "825/825 [==============================] - 17s 21ms/step - loss: 0.1918 - binary_crossentropy: 0.1918\n",
      "Epoch 15/20\n",
      "825/825 [==============================] - 17s 21ms/step - loss: 0.1918 - binary_crossentropy: 0.1918\n",
      "Epoch 16/20\n",
      "825/825 [==============================] - 17s 21ms/step - loss: 0.1917 - binary_crossentropy: 0.1917\n",
      "Epoch 17/20\n",
      "825/825 [==============================] - 17s 21ms/step - loss: 0.1914 - binary_crossentropy: 0.1914\n",
      "Epoch 18/20\n",
      "825/825 [==============================] - 17s 21ms/step - loss: 0.1913 - binary_crossentropy: 0.1913\n",
      "Epoch 19/20\n",
      "825/825 [==============================] - 17s 21ms/step - loss: 0.1908 - binary_crossentropy: 0.1908\n",
      "Epoch 20/20\n",
      "825/825 [==============================] - 17s 21ms/step - loss: 0.1910 - binary_crossentropy: 0.1910\n"
     ]
    }
   ],
   "source": [
    "##We save the weights and repeat the process with a smaller learning rate\n",
    "lr=0.001\n",
    "model=Sequential()\n",
    "model.add(Dense(nn[0], input_dim=6159, activation = 'relu', kernel_initializer=initializers.random_normal(stddev=0.1) ))\n",
    "model.add(Dense(nn[1], activation = 'relu', kernel_initializer=initializers.random_normal(stddev=0.1)))\n",
    "model.add(Dense(nn[1], activation = 'relu',kernel_initializer=initializers.random_normal(stddev=0.1)))\n",
    "model.add(Dense(nn[1], activation = 'relu',kernel_initializer=initializers.random_normal(stddev=0.1)))\n",
    "model.add(Dense(nn[2], activation = 'sigmoid',kernel_initializer=initializers.random_normal(stddev=0.1)))\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizers.adam(lr=lr), metrics = ['binary_crossentropy'])\n",
    "from keras.models import load_model\n",
    "model.load_weights(\"trial.h5\")\n",
    "model.fit(xTrainingData, yTrainingData, epochs=20)\n",
    "model.save_weights('trial.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If we try lower lr afterwards, results are worst in terms of top1, top3..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(xTestData) ##Rounds up and down every prediction to 1 and 0\n",
    "for i in range (0, len (predictions)):\n",
    "    for j in range (0, len (predictions[0])):\n",
    "        if predictions[i][j]<0.5:\n",
    "            predictions[i][j] = 0\n",
    "        else:\n",
    "            predictions[i][j] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussianKernel (vector1, vector2):##Does the gaussian Kernel for two vectors\n",
    "    gamma=0.1\n",
    "    euclideanDistance=np.linalg.norm(vector1-vector2)\n",
    "    kernelValue=np.exp(-gamma*(euclideanDistance**2))\n",
    "    return kernelValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = np.zeros((206, 206))##Creates the ouputfile ready to be opened with analysing Scores notebook\n",
    "for i in range (0, 206):\n",
    "    for j in range (0, 206):\n",
    "        score[i,j]= gaussianKernel(predictions[i],yTestData[j])\n",
    "np.save(\"kerasScore\",score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
